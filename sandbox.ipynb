{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# from IPython.display import Audio \n",
    "# from vscode_audio import Audio\n",
    "import IPython.display\n",
    "import librosa\n",
    "import librosa.display\n",
    "import re\n",
    "\n",
    "def myAudio(audio: np.ndarray, sr: int):\n",
    "    \"\"\"\n",
    "    Use instead of IPython.display.Audio as a workaround for VS Code.\n",
    "    `audio` is an array with shape (channels, samples) or just (samples,) for mono.\n",
    "    \"\"\"\n",
    "\n",
    "    if np.ndim(audio) == 1:\n",
    "        channels = [audio.tolist()]\n",
    "    else:\n",
    "        channels = audio.tolist()\n",
    "\n",
    "    return IPython.display.HTML(\"\"\"\n",
    "        <script>\n",
    "            if (!window.audioContext) {\n",
    "                window.audioContext = new AudioContext();\n",
    "                window.playAudio = function(audioChannels, sr) {\n",
    "                    const buffer = audioContext.createBuffer(audioChannels.length, audioChannels[0].length, sr);\n",
    "                    for (let [channel, data] of audioChannels.entries()) {\n",
    "                        buffer.copyToChannel(Float32Array.from(data), channel);\n",
    "                    }\n",
    "            \n",
    "                    const source = audioContext.createBufferSource();\n",
    "                    source.buffer = buffer;\n",
    "                    source.connect(audioContext.destination);\n",
    "                    source.start();\n",
    "                }\n",
    "            }\n",
    "        </script>\n",
    "        <button onclick=\"playAudio(%s, %s)\">Play</button>\n",
    "    \"\"\" % (json.dumps(channels), sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wavfile.read('bass_electronic_018-022-100.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('..\\examples.json') as what_file:\n",
    "#     readit = json.load(what_file)\n",
    "\n",
    "# train = pd.DataFrame.from_dict(readit).transpose().groupby(by='instrument_str', as_index=True)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data, rate = librosa.load('bass_synthetic_033-082-100.wav')\n",
    "librosa.display.waveshow(data, sr=rate)\n",
    "display(myAudio(data, rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame(os.listdir()).set_axis(['wavfile'], axis=1)\n",
    "cat = [None]*meta.size\n",
    "for i in range(meta.size):\n",
    "    cat[i] = re.split(\"_\", re.sub(\"_\", \":\", meta.wavfile[i], 1))[0]\n",
    "meta['label'] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = meta.label.unique()[:10]\n",
    "choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    c = choice[i]\n",
    "    train = pd.concat([train, meta.query(\"label == @c\").sample(40)], ignore_index=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame()\n",
    "X = [None]*train.wavfile.size\n",
    "y = train.label\n",
    "\n",
    "def scaledNNfeatures(filename):\n",
    "    data, rate = librosa.load(filename)\n",
    "    return np.mean(librosa.feature.mfcc(y=data, sr=rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "for i in range(train.wavfile.size):\n",
    "    X[i] = scaledNNfeatures(train.wavfile[i])\n",
    "    X[i] = X[i].reshape(40)\n",
    "    y[i] = train.label[i]\n",
    "\n",
    "features_df['features'] = X\n",
    "features_df['label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import scipy\n",
    "#import numpy\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# X = np.array(features_df.features)\n",
    "#y = scipy.sparse.coo_matrix(to_categorical(LabelEncoder().fit_transform(features_df.label)))\n",
    "#y = y.toarray().reshape(400,10)\n",
    "# features_df.drop('label', axis=1, inplace=True)\n",
    "# features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_df.to_csv('../bool_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#tensor_features = tf.Tensor(features_df, dtype=int)\n",
    "# tensor_features = tf.convert_to_tensor(features_df, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=y.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 3\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = pd.read_csv('mfcc_send.csv')\n",
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(columns=list(range(40)))\n",
    "# new_data.set_index(list(range(15000)))\n",
    "# new_data[new_data.columns] = [[0]*15000]*40\n",
    "for i in list(range(40)):\n",
    "    new_data[new_data.columns[i]] = [0]*15000\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(new_data.columns.size):\n",
    "    for j in range(old.features.size):\n",
    "        new_data[new_data.columns[i]][j] = [float(s) for s in re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", ' '+old.features[j][1:-1])][i]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '+old.features[0][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[float(s) for s in re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", ' '+old.features[0][1:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.split(' ', ' '+old.features[0][1:-2])[0]      # column number is [i] at the right end\n",
    "# new_data['label'] = ([1]*3000 + [2]*3000 + [3]*3000 + [4]*3000 + [5]*3000)\n",
    "# new_data.columns = list(range(41))\n",
    "# new_data.drop(['label'], axis=1, inplace=True)\n",
    "# new_data\n",
    "new_data.to_csv('new_data.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b01ab086a0250251bc58f227bc2df0f4eb10b9c597481772f2c02bd8a1021fb1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
